{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Create Tri-gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.emma.', '.olivia.', '.ava.', '.isabella.', '.sophia.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only lower-case English letters\n",
    "names_text = open(\"../names.txt\", \"r\").read()\n",
    "words = [f\".{name}.\" for name in names_text.splitlines()]\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '.', 2, 'b')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat encoding and decoding dictionaries\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "ctoi = {c: i for i, c in enumerate(chars)}\n",
    "itoc = {i: c for i, c in enumerate(chars)}\n",
    "ctoi['.'], itoc[0], ctoi['b'], itoc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(805.), tensor(1.))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = torch.zeros(len(chars), len(chars), len(chars))  # Tri-gram\n",
    "for word in words:\n",
    "    for i in range(len(word) - 2):\n",
    "        # count how many times 3 characters appear together\n",
    "        a, b, c = word[i], word[i + 1], word[i + 2]\n",
    "        N[ctoi[a], ctoi[b], ctoi[c]] += 1\n",
    "\n",
    "N = N + 1  # Laplace smoothing\n",
    "\n",
    "N[ctoi['a'], ctoi['n'], ctoi['a']], N[ctoi['x'], ctoi['q'], ctoi['w']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the tri-gram matrix to get the probability\n",
    "N = N.float()  # convert to float\n",
    "P = N / N.sum(dim=2, keepdim=True)  # we want P[i][j].sum() == 1\n",
    "P[14, 23].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1473), tensor(0.0370))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[ctoi['a'], ctoi['n'], ctoi['a']], P[ctoi['x'], ctoi['q'], ctoi['w']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ithia\n",
      "ilynna\n",
      "ikon\n",
      "ivivi\n",
      "itacehlocama\n"
     ]
    }
   ],
   "source": [
    "def generate_name_stochastically(P, first_letter):\n",
    "    name = \".\" + first_letter\n",
    "    while True:\n",
    "        i, j = ctoi[name[-2]], ctoi[name[-1]]\n",
    "        k = torch.multinomial(P[i][j], 1).item()\n",
    "        name += itoc[k]\n",
    "        if name[-1] == \".\":\n",
    "            break\n",
    "    return name[1:-1]\n",
    "\n",
    "for i in range(5):\n",
    "    name = generate_name_stochastically(P, first_letter=\"i\")\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0927)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate the mean of negative log likelihood (loss function)\n",
    "nll = 0\n",
    "n = 1\n",
    "for word in words:\n",
    "    for i in range(len(word) - 2):\n",
    "        a, b, c = word[i], word[i + 1], word[i + 2]\n",
    "        n += 1\n",
    "        likelihood = P[ctoi[a], ctoi[b], ctoi[c]]\n",
    "        nll -= torch.log(likelihood)\n",
    "\n",
    "nll / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
